# Equality

&mdash; [_Deux Conceptions du Racisme_ by Justin Veilleux](20230407164617-deux_conceptions_du_raisme.pdf)

&mdash; <https://youtu.be/aMcjxSThD54>

&mdash; <https://english.stackexchange.com/questions/100576/whats-the-difference-between-just-and-fair>

it seems that _equality_ can mean both _equality of process_ and _equality of outcome_ &mdash; me; assuming an inequal starting point, they are mutually exclusive. it could be argued that the former is _fair_ while the latter is _just_. consequently, a unjust outcome does not imply an unfair process and a fair process does not imply a just outcome

> **example** it can be argued that gender is a [[proxy]] to a myriad of characteristics that cause more men than women to be CEOs; it is an exmple of _outcome in[[equality]]_ but is not a proof of _process in[[equality]]_. moreover, _process [[equality]]_ would not guarantee _outcome [[equality]]_ because of fundamental intrinsic differences between the genders; me and <https://youtu.be/aMcjxSThD54?t=331> and <https://youtu.be/aMcjxSThD54?t=725>

given as only information a few [[proxy]]es, the _optimal_ process for the [[optimization]] of a given metric is likely to be _unfair_. consequently, _fair_ processes may lead to _suboptimal_ results

> **example** let's assume more men than women are engineers. given pictures of people, an _unfair_ yet arguably _optimal_ process to guess which people are engineers is to only select the men. a _fair_ process could consist of selecting people at random; the _fair_ process would lead to a _suboptimal_ result
