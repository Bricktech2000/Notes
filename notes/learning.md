# Learning

**see** [[memory]], [[invest]], [[durability]], [[fossilization]]

**see** _learning techniques_ [[active recall]], [[spaced repetition]], [[interleaving]]

--- <https://youtu.be/5eW6Eagr9XA>

> **resource** _learn how to study smart_ by Marty Lobdell --- <https://youtu.be/IlU-zDU6aQ0>

> **resource** _Guessing the Teacher's Password_, on the distinction between _passwords_ and _explanations_ --- <https://www.readthesequences.com/Guessing-The-Teachers-Password>

[[learning]] requires **repeated attempts** and **deliberate practice** in a _high-validity environment_, which means: --- [[6854a88e-e810-8008-a280-e93598dd7b91]]

- [[cue]]s reliably correlate with outcomes
- consistent statistical regularities exist
- feedback is accurate and timely

> **example** it shouldn't be so surprising people can measure bolts by eye because it checks all the boxes of a highly learnable skill

sometimes you can conjure up [[learning]] out of thin air just by giving yourself access to timely feedback

> **example** read your grocery receipts right before putting groceries away (an example of _[[habit]] stacking_) to get better at predicting where your [[money]] is going

> **example** read writeups after participating in a CTF to identify inefficiencies in your solutions

an easy one to forget is you get good at what you practice, so practice what you're trying to get good at

> **example** if you want to get good at flashing bouldering problems, practice flashing bouldering problems. you could give yourself one attempt per problem per session, or you could create a culture where your friends tell eachother not what problems they've sent, but how many attempts it took them

be wary of "experts" in low-validity [[fields]]---arguably, it's a contradiction in terms, because low-validity environments are not conducing to the development of expertise

> **example** _political scientist Philip Tetlock picked 284 people who make their living commenting or offering advice on political or economic trends. this included journalists, foreign policy specialists, economists and intelligence analysts. over two decades he peppered them with questions [...] and by the end of the study Tetlock had quantified 82361 predictions. these experts, most of whom had post-graduate degrees, performed worse [...] than random chance._ --- <https://youtu.be/5eW6Eagr9XA?t=319>

> **note** admission officers and recruitment specialists don't get timely feedback on their decisions, so they kinda suck. but why not just give them timely feedback? say, every few applicants, silently give them a "dummy" applicant that previously worked at the company or studied at the university, and after they make their decision, reveal the historical performance of the dummy applicant to serve as feedback
